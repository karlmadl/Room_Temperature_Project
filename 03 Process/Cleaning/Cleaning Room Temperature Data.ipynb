{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning Temperature Data\r\n",
    "### Karl Madl\r\n",
    "### 2021 September 01"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll import the *Pandas* and *mysq.connector* packages to import database data into a Pandas dataframe which we'll name **raw_temperature_df** (raw temperature dataframe). We'll also import a dictionary containing the login information to the MySQL server as **CREDS**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that we'll leave **id** out of our SQL *SELECT* statement since Pandas provides automatic row indexing. These new indexes will be equal to the orignal **id** of the data minus 1."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import mysql.connector as connector\r\n",
    "from database_credentials import MySQL_credentials as CREDS\r\n",
    "\r\n",
    "connection = connector.connect(\r\n",
    "    host = CREDS['host'],\r\n",
    "    user = CREDS['user'],\r\n",
    "    password = CREDS['password'],\r\n",
    "    database = CREDS['database']\r\n",
    ")\r\n",
    "\r\n",
    "raw_temperature_df = pd.read_sql(f\"SELECT inside_temperature, outside_temperature, time, date FROM {CREDS['table']}\", con=connection)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "\r\n",
    "## Data Types"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll check the shape of the dataframe to confirm we imported all of the rows. We should have, at the time of writing, 347 rows. This is confirmed by accessing the *shape* attribute."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_temperature_df.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll check that our columns (attributes) are of the proper data type by accessing the *dtypes* attribute of the dataframe. In this case, the **date** column was incorrectly typed as an *object* (string) since Pandas doesn't support the *date* type that the **date** column was stored as in the database."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that Pandas also doesn't support the *time* type that the **time** column is stored as so it has been converted to a *timedelta*. This is fine for the purposes of our analysis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_temperature_df.dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To convert the **date** column to a *datetime* we'll use the *to_datetime* function that Pandas offers. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another route to take would be re-querying the data, *CAST*ing the **date** column as *datetime* but that would be less computation efficient and less time efficient. This would also likely muddle the clarity of the data cleaning process."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Secondly, we'll create extra columns containing the year, month, and day of the month for each observation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_temperature_df['date'] = pd.to_datetime(raw_temperature_df['date'])  # convert date column type from object to datetime\r\n",
    "\r\n",
    "raw_temperature_df['year'] = raw_temperature_df['date'].map(lambda x: x.year)\r\n",
    "raw_temperature_df['month'] = raw_temperature_df['date'].map(lambda x: x.month)\r\n",
    "raw_temperature_df['day'] = raw_temperature_df['date'].map(lambda x: x.day)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A final check of the data types in each column reveals exactly the desired outcome. The **year**, **month**, and **day** columns are as integers but this is fine for our purposes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_temperature_df.dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "While data is only uploaded to the database if there are no null values in the observation, we should remove rows in the dataframe containing NaN values, the Pandas equivalent for null values, to be confident we won't raise any arithmetic exceptions during the analysis phase. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_temperature_df.dropna(axis='index')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "## Consistency of Data and Duplicates"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We should make sure that the amount of data in each group that we'll be analyzing is consistent so as not to introduce bias into our analysis.\r\n",
    "This isn't a necessary prerequisite if we wish to perform an ANOVA test, so long as the variance between the groups is similar. [^1] For this reason we'll also check the variance of the groups by looking at the standard deviation for each. Let's first start with the **time** groups."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_temperature_df.groupby(['time']).describe().loc[:, ['inside_temperature', 'outside_temperature']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first thing to notice is that, there are some observations that were recorded at odd times. This could be caused due to a power outage delaying the running of the data collection script or an error in uploading to the database. We can allow for a margin of error of a minute, since temperature changes are typically negligible on the timescales of seconds. Upon further examination, the discrepancy between the count of observations at midnight (00:00:00) and the other times seems a bit conspicuous, especially if we were to assign the times between 00:00:04 and 00:00:20 to also be midnight observations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A more meticulous manual look at the data shows an interesting pattern between indices 64 and 80 and it becomes clear what occurred. From the latter half of 2021-07-06 through 2021-07-08, all times were formatted incorrectly and thus we can adjust them using the *replace* Pandas function. We'll then use the same function to adjust the 04:01:00, 08:01:00, and 20:01:00 timed observations. We'll also create a new dataframe **fixed_times_df** to move forward."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we'll use the *drop* function to eliminate the observation recorded at 13:19:00 and use *drop_duplicates* based on **date** and **time** to eliminate any conflicting observations and repeated entries."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fixed_times_df = raw_temperature_df.replace(\r\n",
    "    to_replace=pd.to_timedelta(['00:00:04', '00:00:08', '00:00:12', '00:00:16', '00:00:20']), \r\n",
    "    value=pd.to_timedelta(['04:00:00', '08:00:00', '12:00:00', '16:00:00', '20:00:00']),\r\n",
    "    )\r\n",
    "\r\n",
    "fixed_times_df.replace(\r\n",
    "    to_replace=pd.to_timedelta(['04:01:00', '08:01:00', '20:01:00']), \r\n",
    "    value=pd.to_timedelta(['04:00:00', '08:00:00', '20:00:00']),\r\n",
    "    inplace=True\r\n",
    "    )\r\n",
    "\r\n",
    "fixed_times_df.drop(fixed_times_df[fixed_times_df['time'] == pd.to_timedelta('13:19:00')].index, inplace=True)\r\n",
    "\r\n",
    "fixed_times_df.drop_duplicates(['date', 'time'], keep='first', inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking again on the description of the dataframe, grouped by time, we now have more consistent group sizes and standard deviations (a measure of variance) across groups."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fixed_times_df.groupby(['time']).describe().loc[:, ['inside_temperature', 'outside_temperature']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll check the same, now grouping by **day**, **month**, and **year** (which wil have the same output as **season** since data collection has only occurred during summer). All of these have consistent standard deviations and ranges. There is some inconsistency between **day** groups and **month** groups but, because the variance in the temperature readings is similar, we can proceed. It should be note, however, that any statistical tests run will only have the power based on the smallest group in the group pool."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fixed_times_df.groupby(['day']).describe().loc[:, ['inside_temperature', 'outside_temperature']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fixed_times_df.groupby(['month']).describe().loc[:, ['inside_temperature', 'outside_temperature']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fixed_times_df.groupby(['year']).describe().loc[:, ['inside_temperature', 'outside_temperature']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "## Conclusion"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data is now sufficiently cleaned and may be used for analysis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clean_df = fixed_times_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "481fbf580910604266a6f69ab2a40cb7227f9edac014d0d3ebcb939174d08ed7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}